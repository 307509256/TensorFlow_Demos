{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "org_train_file = 'training.1600000.processed.noemoticon.csv'\n",
    "org_test_file = 'testdata.manual.2009.06.14.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extact fields\n",
    "def use_field(filename_in,filename_out):\n",
    "    df=pd.read_csv(filename_in, \n",
    "                   encoding='latin-1',\n",
    "                   buffer_lines=10000,\n",
    "                   header=None,\n",
    "                   names=[\"opinion\",\"_1\",\"_2\",\"_3\",\"_4\",\"text\"],\n",
    "                   usecols=[\"opinion\",\"text\"],\n",
    "                   error_bad_lines=False,\n",
    "                   dtype=np.str)\n",
    "    df[\"negative\"]=df.opinion.apply(lambda x: 1 if x==\"0\" else 0)\n",
    "    df[\"neutral\"]=df.opinion.apply(lambda x: 1 if x==\"2\" else 0)\n",
    "    df[\"positive\"]=df.opinion.apply(lambda x:1 if x==\"4\" else 0)\n",
    "    df.reindex(columns=[\"negative\",\"neutral\",\"positive\",\"text\"]) \\\n",
    "      .to_csv(filename_out,encoding=\"utf-8\",sep=\"|\",index=False)\n",
    "use_field(org_train_file,\"train.csv\")\n",
    "use_field(org_test_file,\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n"
     ]
    }
   ],
   "source": [
    "#make lexicon\n",
    "def mk_lexicon(filename_in):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df=pd.read_csv(filename_in,\n",
    "                  encoding=\"utf-8\",\n",
    "                  sep=\"|\",\n",
    "                  buffer_lines=10000,\n",
    "                  header=0,\n",
    "                  usecols=[\"text\"])\n",
    "    word_count={}\n",
    "    def pipeline_line(x):  \n",
    "        #line=>word=>word_count\n",
    "        for word in map(lemmatizer.lemmatize,word_tokenize(x.lower())):\n",
    "            if word in word_count:\n",
    "                word_count[word]+=1\n",
    "            else:\n",
    "                word_count[word]=1\n",
    "    for i,line in enumerate(df.text):\n",
    "        if not i%100000:\n",
    "            print(i)\n",
    "        pipeline_line(line)\n",
    "    lex=[item[0] for item in sorted(word_count.items(),key=lambda x:x[1]) if 100<item[1]<100000 ]\n",
    "    return lex\n",
    "lex=mk_lexicon(\"train.csv\")\n",
    "with open('lexcion.pickle', 'wb') as f:\n",
    "    pickle.dump(lex, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
