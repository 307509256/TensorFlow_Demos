{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#download data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"/tmp/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 10), (55000, 784), (10000, 10), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shapes\n",
    "mnist.train.labels.shape,mnist.train.images.shape,\\\n",
    "mnist.test.labels.shape,mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_output_layer=10\n",
    "def convolutional_neural_network(data):\n",
    "    weights={\"w_conv1\":tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "            \"w_conv2\":tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "            \"w_fc\":tf.Variable(tf.random_normal([7*7*64,1024])),\n",
    "            \"out\":tf.Variable(tf.random_normal([1024,n_output_layer]))}\n",
    "    biases={\"b_conv1\":tf.Variable(tf.random_normal([32])),\n",
    "           \"b_conv2\":tf.Variable(tf.random_normal([64])),\n",
    "           \"b_fc\":tf.Variable(tf.random_normal([1024])),\n",
    "           \"out\":tf.Variable(tf.random_normal([n_output_layer]))}\n",
    "    data=tf.reshape(data,[-1,28,28,1])\n",
    "    \n",
    "    conv1=tf.nn.relu(tf.add(tf.nn.conv2d(data,weights[\"w_conv1\"],\n",
    "        strides=[1,1,1,1],padding=\"SAME\"),biases[\"b_conv1\"]))\n",
    "    conv1=tf.nn.max_pool(conv1,ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                        padding=\"SAME\")\n",
    "    conv2=tf.nn.relu(\n",
    "            tf.add(tf.nn.conv2d(conv1,weights[\"w_conv2\"],\n",
    "        strides=[1,1,1,1],padding=\"SAME\"),biases[\"b_conv2\"]))\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    fc = tf.reshape(conv2, [-1, 7 * 7 * 64])\n",
    "    fc = tf.nn.relu(tf.add(tf.matmul(fc, weights['w_fc']), biases['b_fc']))\n",
    "    output=tf.add(tf.matmul(fc,weights[\"out\"]),biases[\"out\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "X=tf.placeholder(\"float\",[None,28*28])\n",
    "Y=tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 60417.1796875\n",
      "accuray: 0.1508\n",
      "0 : 775272.762939\n",
      "accuray: 0.832\n",
      "0 : 967669.355957\n",
      "accuray: 0.8856\n",
      "0 : 1102471.52781\n",
      "accuray: 0.9185\n",
      "0 : 1220499.4435\n",
      "accuray: 0.9327\n",
      "0 : 1308356.97851\n",
      "accuray: 0.9337\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(X,Y):\n",
    "    predict=convolutional_neural_network(X)\n",
    "    cost_func=tf.reduce_mean(tf.nn\n",
    "                             .softmax_cross_entropy_with_logits(predict,Y))\n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost_func)   \n",
    "    \n",
    "    epochs=1\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.initialize_all_variables())\n",
    "        epoch_loss=0\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "                x,y=mnist.train.next_batch(batch_size)\n",
    "                _,c=session.run([optimizer,cost_func],feed_dict={X:x,Y:y})\n",
    "                epoch_loss+=c\n",
    "                if not i%100:\n",
    "                    print(epoch,\":\",epoch_loss)\n",
    "                    correct_vector=tf.equal(tf.argmax(predict,1),tf.argmax(Y,1))\n",
    "                    accuray=tf.reduce_mean(tf.cast(correct_vector,\"float\"))\n",
    "                    print(\"accuray:\",accuray.eval({X:mnist.test.images,Y:mnist.test.labels}))\n",
    "train_neural_network(X,Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
